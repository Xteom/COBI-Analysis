{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80fa4218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f340309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_elapsed(function, *args):\n",
    "    start = time.perf_counter()\n",
    "    function(*args)\n",
    "    end = time.perf_counter()\n",
    "    print(f\"Time elapsed: {end - start:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a7bea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gather_cicese_data(year_from, directory_to, location=\"isla_cedros\"):\n",
    "    location_dict = {\"isla_cedros\":\"ICDN\", \"guerrero_negro\":\"GRON\"}\n",
    "    \n",
    "    # Column names obtained from CICESE files metadata. None of this files have a header\n",
    "    columns=[\"anio\",\"mes\",\"dia\",\"hora\",\"minuto\",\"segundo\",\n",
    "             \"id_estacion\",\"voltaje_sistema\",\"nivel_mar_leveltrol\",\"nivel_mar_burbujeador\",\n",
    "             \"sw_1\",\"sw_2\",\"temperatura_agua\",\"nivel_mar_ott_rsl\", \"radiacion_solar\",\n",
    "             \"direccion_viento\", \"magnitud_viento\", \"temperatura_aire\",\"humedad_relativa\",\n",
    "             \"presion_atmosferica\",\"precipitacion\",\"voltaje_estacion_met\",\"nivel_mar_sutron\"]\n",
    "\n",
    "    # df is the dataframe that will allocate all the data\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # We set the directory where we will download the data\n",
    "    directory_path = directory_to + location\n",
    "    if not os.path.isdir(directory_path):\n",
    "        os.mkdir(directory_path)\n",
    "\n",
    "    os.chdir(directory_path) #changes the active dir - this is where downloaded files will be saved to\n",
    "    \n",
    "    # We have data from 2011 to 2021. \n",
    "    years = list(range(year_from, datetime.now().year+1))\n",
    "    for year in years:\n",
    "    \n",
    "        # Define the URL of the directory containing the .dat files\n",
    "        url = \"http://redmar.cicese.mx/emmc/DATA/\"+location_dict[location]+\"/MIN/\"+str(year)+\"/\"\n",
    "\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Extract the HTML content of the response\n",
    "        html_content = response.content.decode('utf-8')\n",
    "\n",
    "        # Find all the .dat file names in the HTML content\n",
    "        dat_files = []\n",
    "        for line in html_content.split('\\n'):\n",
    "            if '.dat' in line:\n",
    "                filename = line.split('href=\"')[1][:15]\n",
    "                dat_files.append(filename)\n",
    "    \n",
    "\n",
    "        # Download each .dat file and save it in the data directory\n",
    "        for filename in dat_files:\n",
    "            try:\n",
    "                file_url = url + filename\n",
    "                file_path = os.path.join(directory_path, filename)\n",
    "                response = requests.get(file_url)\n",
    "                \n",
    "                if not os.path.exists(file_path):\n",
    "                    with open(file_path, 'wb') as f:\n",
    "                        f.write(response.content)\n",
    "\n",
    "\n",
    "                    # Open the downloaded file and read its content\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        content = f.read()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(filename, \"no se agreg√≥ por: \", e)\n",
    "                \n",
    "        # Rename df columns with the ones defined before\n",
    "        dict_columns = {}\n",
    "        for col, i in zip(columns, range(len(columns))):\n",
    "            dict_columns[i] = col\n",
    "        dict_columns\n",
    "        df = df.rename(columns=dict_columns)\n",
    "\n",
    "        # Export csv\n",
    "        df.to_csv(str(year_from)+\"_\"+location+\".csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32427182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cicese_data(place, directory_from):\n",
    "    columns=[\"anio\",\"mes\",\"dia\",\"hora\",\"minuto\",\"segundo\",\n",
    "             \"id_estacion\",\"voltaje_sistema\",\"nivel_mar_leveltrol\",\"nivel_mar_burbujeador\",\n",
    "             \"sw_1\",\"sw_2\",\"temperatura_agua\",\"nivel_mar_ott_rsl\", \"radiacion_solar\",\n",
    "             \"direccion_viento\", \"magnitud_viento\", \"temperatura_aire\",\"humedad_relativa\",\n",
    "             \"presion_atmosferica\",\"precipitacion\",\"voltaje_estacion_met\",\"nivel_mar_sutron\"]\n",
    "    # Set the directory path\n",
    "    dir_path = os.path.join(directory_from, place)\n",
    "    \n",
    "    # Get a list of all .dat files in the directory\n",
    "    dat_files = glob.glob(os.path.join(dir_path, \"*.dat\"))\n",
    "\n",
    "    # Initialize an empty list to store the dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Loop through each file and read it into a dataframe\n",
    "    for file in dat_files:\n",
    "        df = pd.read_csv(file, lineterminator='\\n', delim_whitespace=True, header=None)\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all the dataframes into a single dataframe\n",
    "    result_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    \n",
    "    # Rename df columns with the ones defined before\n",
    "    dict_columns = {}\n",
    "    for col, i in zip(columns, range(len(columns))):\n",
    "        dict_columns[i] = col\n",
    "    dict_columns\n",
    "    result_df = result_df.rename(columns=dict_columns)\n",
    "\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae065079",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_to = \"C:\\\\Users\\\\javi2\\\\Documents\\\\CD_aplicada_1\\\\COBI\\\\etl\\\\data\\\\cicese\\\\raw\\\\\"\n",
    "# gather_cicese_data(2021, directory_to=directory_to, location=\"guerrero_negro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e855723",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_from = \"C:\\\\Users\\\\javi2\\\\Documents\\\\CD_aplicada_1\\\\COBI\\\\etl\\\\data\\\\cicese\\\\raw\\\\\"\n",
    "directory_to = \"C:\\\\Users\\\\javi2\\\\Documents\\\\CD_aplicada_1\\\\COBI\\\\etl\\\\data\\\\cicese\\\\processed\\\\\"\n",
    "\n",
    "estacion = \"guerrero_negro\"\n",
    "df = read_cicese_data(estacion, directory_from)\n",
    "df = df.groupby([\"anio\", \"mes\", \"dia\"]).median()\n",
    "df[\"estacion\"] = estacion\n",
    "df = df.reset_index()\n",
    "df[\"mes\"] = df.apply(lambda x: \"0\"+str(x[\"mes\"]) if x[\"mes\"] < 10 else x[\"mes\"], axis=1)\n",
    "df[\"dia\"] = df.apply(lambda x: \"0\"+str(x[\"dia\"]) if x[\"dia\"] < 10 else x[\"dia\"], axis=1)\n",
    "df[\"date\"] = df.apply(lambda x: str(x[\"anio\"])+\"-\"+str(x[\"mes\"])+\"-\"+str(x[\"dia\"]), axis=1)\n",
    "\n",
    "df = df[[\"estacion\", \"nivel_mar_leveltrol\", \"nivel_mar_burbujeador\", \"nivel_mar_ott_rsl\", \"nivel_mar_sutron\", \n",
    "         \"temperatura_agua\", \"radiacion_solar\",\"direccion_viento\",\"magnitud_viento\",\"temperatura_aire\",\n",
    "         \"humedad_relativa\",\"presion_atmosferica\",\"precipitacion\", \"date\"]]\n",
    "\n",
    "df.to_csv(directory_to+estacion+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9e46630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d0caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "887271e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    # set up a connection to the database\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        database=\"cobi\",\n",
    "        user=\"postgres\",\n",
    "        password=\"admin\"\n",
    "    )\n",
    "\n",
    "    # create a database cursor\n",
    "    cur = conn.cursor()\n",
    "\n",
    "\n",
    "    # Iterate over the DataFrame rows and insert them into the PostgreSQL table\n",
    "    for i, row in df.iterrows():\n",
    "        cur.execute(\"\"\"INSERT INTO cicese (estacion, nivel_mar_leveltrol, nivel_mar_burbujeador, nivel_mar_ott_rsl, \n",
    "        nivel_mar_sutron, temperatura_agua, radiacion_solar,direccion_viento,magnitud_viento,temperatura_aire,\n",
    "        humedad_relativa,presion_atmosferica,precipitacion,date) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\",\n",
    "                    (row[\"estacion\"], row[\"nivel_mar_leveltrol\"], row[\"nivel_mar_burbujeador\"], row[\"nivel_mar_ott_rsl\"], \n",
    "                     row[\"nivel_mar_sutron\"], row[\"temperatura_agua\"], row[\"radiacion_solar\"], row[\"direccion_viento\"],\n",
    "                     row[\"magnitud_viento\"], row[\"temperatura_aire\"], row[\"humedad_relativa\"], row[\"presion_atmosferica\"],\n",
    "                     row[\"precipitacion\"], row[\"date\"]))\n",
    "\n",
    "    # Commit the changes and close the database connection\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\" error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e530a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a75504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6218ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
