{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "04084746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from typing import Dict, Set\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# dir = \"C:/Users/javi2/Documents/CD_aplicada_1/COBI/etl/data/globcolour/processed/aerosol_optical_thickness_over_water/\"\n",
    "\n",
    "# # read in the CSV files\n",
    "# df1 = pd.read_csv(dir+'L3m_20170101__GLOB_100_AVW-MODVIR_T865_DAY_00_clean.csv')\n",
    "# df2 = pd.read_csv(dir+'L3m_20170102__GLOB_100_AVW-MODVIR_T865_DAY_00_clean.csv')\n",
    "# df3 = pd.read_csv(dir+'L3m_20170103__GLOB_100_AVW-MODVIR_T865_DAY_00_clean.csv')\n",
    "\n",
    "# # merge the dataframes\n",
    "# merged_df = pd.concat([df1, df2, df3])\n",
    "\n",
    "# merged_df = merged_df.dropna(subset = [\"T865_mean\"]).iloc[:, [1,2,3,5,6]]\n",
    "# merged_df.to_csv(\"merged_data.csv\")\n",
    "# merged_df[\"variable\"] = \"aerosol_optical_thickness_over_water\"\n",
    "# merged_df\n",
    "\n",
    "\n",
    "def read_variable_dict(filename: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Reads the variable dictionary from a CSV file and returns it as a dictionary.\n",
    "    The CSV file should have a \"variable\" column and a \"file_format\" column.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        variable_dict = {row['variable']: row['file_format'] for row in reader}\n",
    "    return variable_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263f497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f93e1078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secchi_disk_depth error: No objects to concatenate\n"
     ]
    }
   ],
   "source": [
    "for variable in read_variable_dict(\"variable_dict.csv\").keys():\n",
    "    \n",
    "        try:\n",
    "            # Set the directory where the CSV files are located\n",
    "            dir_path = \"C:/Users/javi2/Documents/CD_aplicada_1/COBI/etl/data/globcolour/processed/\"+variable+\"/\"\n",
    "\n",
    "            # Use glob to find all CSV files in the directory\n",
    "            all_files = glob.glob(os.path.join(dir_path, \"*.csv\"))\n",
    "\n",
    "            # Concatenate all CSV files into a single Pandas DataFrame\n",
    "            df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "\n",
    "\n",
    "            # create a dictionary to map the old column names to new column names\n",
    "            new_column_names = {}\n",
    "            for column in df.columns:\n",
    "                if \"mean\" in column:\n",
    "                    new_column_names[column] = \"mean\"\n",
    "                if \"error\" in column:\n",
    "                    new_column_names[column] = \"error\"\n",
    "\n",
    "            # rename the columns using the dictionary created above\n",
    "            df.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "            if \"mean\" not in df.columns:\n",
    "                df[\"mean\"] = np.nan\n",
    "\n",
    "            if \"error\" not in df.columns:\n",
    "                df[\"error\"] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Display the concatenated DataFrame\n",
    "            df = df.dropna(subset = [\"mean\"])[[\"lat\", \"lon\", \"mean\", \"error\", \"date\"]]\n",
    "\n",
    "\n",
    "            df.to_csv(\"merged_data.csv\")\n",
    "            df[\"variable\"] = variable\n",
    "\n",
    "\n",
    "\n",
    "            # set up a connection to the database\n",
    "            conn = psycopg2.connect(\n",
    "                host=\"localhost\",\n",
    "                database=\"cobi\",\n",
    "                user=\"postgres\",\n",
    "                password=\"admin\"\n",
    "            )\n",
    "\n",
    "            # create a database cursor\n",
    "            cur = conn.cursor()\n",
    "\n",
    "            # Rename the DataFrame columns to match the PostgreSQL table columns\n",
    "            df.columns = [\"lat\", \"lon\", \"mean\", \"error\", \"date\", \"variable\"]\n",
    "\n",
    "            # Iterate over the DataFrame rows and insert them into the PostgreSQL table\n",
    "            for i, row in df.iterrows():\n",
    "                cur.execute(\"INSERT INTO globcolour (lat, lon, mean, error, date, variable) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
    "                            (row[\"lat\"], row[\"lon\"], row[\"mean\"], row[\"error\"], row[\"date\"], row[\"variable\"]))\n",
    "\n",
    "            # Commit the changes and close the database connection\n",
    "            conn.commit()\n",
    "            cur.close()\n",
    "            conn.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(variable + \" error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf3100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
