{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80fa4218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENSM2017.dat\">E no se agregó\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Column names obtained from CICESE files metadata. None of this files have a header\n",
    "columns=[\"anio\",\"mes\",\"dia\",\"hora\",\"minuto\",\"segundo\",\n",
    "         \"id_estacion\",\"voltaje_sistema\",\"nivel_mar_leveltrol\",\"nivel_mar_burbujeador\",\n",
    "         \"sw_1\",\"sw_2\",\"temperatura_agua\",\"nivel_mar_ott_rsl\", \"radiacion_solar\",\n",
    "         \"direccion_viento\", \"magnitud_viento\", \"temperatura_aire\",\"humedad_relativa\",\n",
    "         \"presion_atmosferica\",\"precipitacion\",\"voltaje_estacion_met\",\"nivel_mar_sutron\"]\n",
    "\n",
    "# df is the dataframe that will allocate all the data\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# We have data from 2011 to 2021. \n",
    "for anio in [\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\",\"2020\",\"2021\"]:\n",
    "    # Define the URL of the directory containing the .dat files\n",
    "    url = \"http://redmar.cicese.mx/emmc/DATA/ENSM/MIN/\"+anio+\"/\"\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Extract the HTML content of the response\n",
    "    html_content = response.content.decode('utf-8')\n",
    "\n",
    "    # Find all the .dat file names in the HTML content\n",
    "    dat_files = []\n",
    "    for line in html_content.split('\\n'):\n",
    "        if '.dat' in line:\n",
    "            filename = line.split('href=\"')[1][:15]\n",
    "            dat_files.append(filename)\n",
    "\n",
    "    # Create a directory to store the downloaded files\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "\n",
    "    # Download each .dat file and save it in the data directory\n",
    "    for filename in dat_files:\n",
    "        try:\n",
    "            file_url = url + filename\n",
    "            file_path = os.path.join('data', filename)\n",
    "            response = requests.get(file_url)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "\n",
    "            # Open the downloaded file and read its content\n",
    "            with open(file_path, 'r') as f:\n",
    "                content = f.read()\n",
    "\n",
    "\n",
    "            # Read the downloaded file using pandas and concatenate it to df\n",
    "            df_aux = pd.read_csv(file_path, lineterminator='\\n', delim_whitespace=True, header=None)\n",
    "            df = pd.concat([df,df_aux])\n",
    "        except:\n",
    "            print(filename, \"no se agregó\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe1ad0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e530a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename df columns with the ones defined before\n",
    "dict_columns = {}\n",
    "for col, i in zip(columns, range(len(columns))):\n",
    "    dict_columns[i] = col\n",
    "dict_columns\n",
    "df = df.rename(columns=dict_columns)\n",
    "\n",
    "# Export csv\n",
    "df.to_csv(\"cicese_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a75504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export 1000 rows to have a preview (in Github)\n",
    "df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de6218ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anio', 'mes', 'dia', 'hora', 'minuto', 'segundo', 'id_estacion',\n",
       "       'voltaje_sistema', 'nivel_mar_leveltrol', 'nivel_mar_burbujeador',\n",
       "       'sw_1', 'sw_2', 'temperatura_agua', 'nivel_mar_ott_rsl',\n",
       "       'radiacion_solar', 'direccion_viento', 'magnitud_viento',\n",
       "       'temperatura_aire', 'humedad_relativa', 'presion_atmosferica',\n",
       "       'precipitacion', 'voltaje_estacion_met', 'nivel_mar_sutron'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
